#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Copyright (C) Red Hat, Inc
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.


from dci_analytics import elasticsearch as es
from dci_analytics.synchronizers import jobs

from kombu import Connection, Exchange, Queue
from kombu.mixins import ConsumerMixin

import logging
import os
import sys

_INDEX = "jobs"

AMQP_BROKER_URL = os.getenv("AMQP_BROKER_URL", "amqp://guest:guest@rabbitmq:5672//")
LOGGING_LEVEL = logging.INFO

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
    )

    formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(name)s: %(message)s")
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(LOGGING_LEVEL)
    console_handler.setFormatter(formatter)

    root_logger = logging.getLogger()
    root_logger.setLevel(LOGGING_LEVEL)
    root_logger.handlers.clear()
    root_logger.addHandler(console_handler)

    kombu_logger = logging.getLogger("kombu")
    kombu_logger.setLevel(LOGGING_LEVEL)
    kombu_logger.handlers.clear()
    kombu_logger.addHandler(console_handler)

    kombu_transport_logger = logging.getLogger("kombu.transport")
    kombu_transport_logger.setLevel(LOGGING_LEVEL)
    kombu_transport_logger.handlers.clear()
    kombu_transport_logger.addHandler(console_handler)


class Worker(ConsumerMixin):
    def __init__(self, connection, queues):
        self.connection = connection
        self.queues = queues

    def get_consumers(self, Consumer, channel):
        return [Consumer(queues=self.queues,
                         callbacks=[self.on_message])]

    def on_message(self, body, message):
        event = body["event"]
        job_id = body["job"]["id"]
        logging.info(f"Handle job event {event}: job_id {job_id}")

        latest_index_alias = es.get_latest_index_alias(_INDEX)
        logging.info(f"latest_index_alias: {latest_index_alias}")
        if latest_index_alias:
             jobs.sync_one_job(latest_index_alias, body["job"])
        else:
             new_index_name = es.generate_new_index_name(_INDEX)
             logging.info(f"new index created: '{new_index_name}'")
             jobs.sync_one_job(new_index_name, body["job"])
             new_alias = es.add_alias_to_index("jobs", new_index_name)
             logging.info(f"new alias '{new_alias}' added for index: '{new_index_name}'")
        message.ack()


if __name__ == '__main__':

    setup_logging()

    exchange_name = "dci.analytics.exchange"
    exchange_type = "direct"
    queue_name = "dci.analytics.queue"
    routing_key = "dci.analytics.jobs"

    exchange = Exchange(exchange_name, type=exchange_type)
    queues = [Queue(queue_name, exchange, routing_key=routing_key)]

    logging.info("worker waiting for messages")
    logging.info(f"exchange: {exchange_name}, type: {exchange_type}")
    logging.info(f"queue: {queue_name}, routing_key: {routing_key}")

    with Connection(AMQP_BROKER_URL, heartbeat=4) as conn:
            worker = Worker(conn, queues)
            worker.run()
